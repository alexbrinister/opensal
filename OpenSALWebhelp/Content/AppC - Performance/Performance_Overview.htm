<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd" MadCap:lastBlockDepth="4" MadCap:lastHeight="8381" MadCap:lastWidth="600" MadCap:ignoredWords="L1;e600;864x" MadCap:disableMasterStylesheet="true" MadCap:tocPath="" MadCap:InPreviewMode="false" MadCap:RuntimeFileType="Topic" MadCap:TargetType="WebHelp" MadCap:liveHelp="SguYFncQ5v9ug1+HmmvB5LH9ahJPL+VtmlxNB9jY/adfo7sjHaVduGuzDEClxnZgjFYuOjmaMSRwC3KJ3WDR+759CJ7FFiB88gHqvaJ2mF8jOOiNDuCB+Gx5kEaVG8YoJ+EtenNSPkjx0Jnf48HRduovXLzUzgQNeUQn9w9UqHtfEWq6NqK0mJmBiX2gLoyvwAWDiHwzr/T0/ld2bi22SeRYlxWMeFbIylMdYfEgQUNerH/HfAIPj7OkAjaF4FD52KW/1k8lHpmKpBBT+bcWCDvnaBvBYjp9wpI4bRxO8YMKHp5J70B3sK32LSxMoWeKYP7yc+TauhqcFnpKkVy6ql3bS51TauahayTkxgf5DC8j0OE+aWwMx0H5D4ek9Ygn6R/fCcLhGnHIsz04/kahvXef78eAJYIUyrmLoswniOfBTfGr4dJKoFKWpNfmq5ZHyX5jJYox01Wejibd+3vsiVOq7P9DAAtvaiVWYn7T8TtBqU8QL5Mok2EqolxWa860uKCrsgX4+BVaBfrap/JNwJgEH39IelCiHB4+1G+3GUpTj7VfRtyGfaBj1Xmz2EN5zXdzJrLm+LZ+viRdWbNjJshnKBBq+ppfWkyZvPPS2QIGgpIPC9PFIa3o3jxEzw5Pr9G1e9TVOofuvwZRDMvmlyFHGRj9QdYGhtheuVXu40sdx+r7ec6/q1Fb8pQ8+Wnsl8TeMMLGowa4xY0bh2QIu3haiQmIpdc3vB59IzRLHr94zYhi6ohxvJkjJOw10Qw9RRgfJbQPhKPArNjl4c0LshbvEiW95OvQdtpuQBvc7Yij8rj92cUiViP9fx74H6XhQ4ISi07QvZ/xXFKj74IABpwAZ/APAMv91JkK/6f3aWfQgJfY3naP9v8S9H4l2DOnD6QE/b1pJRHMezOCFdQJEcxKP8aDi3I0iiDZj+WoyROvJ7L/GziqJf1EWLPYhVBVXFAFGa3GANjNpBVCmQ+AvKAhqwolZfo3LZ+Gsr+8h0Mjkz/CTlVTqMy5f7JKeCRw" MadCap:PathToHelpSystem="../../" MadCap:HelpSystemFileName="Default.xml" MadCap:SearchType="Stem">
    <head>
        <link href="../SkinSupport/MadCap.css" rel="stylesheet" type="text/css" /><title>Obtaining the Best SAL Performance</title>
        <link href="../Resources/TableStyles/o_Code.css" rel="stylesheet" MadCap:stylesheetType="table" />
        <link href="../Resources/TableStyles/o_Note.css" rel="stylesheet" MadCap:stylesheetType="table" />
        <link href="../Resources/TableStyles/p_Invisible.css" rel="stylesheet" MadCap:stylesheetType="table" />
        <link href="../Resources/TableStyles/o_Invisible.css" rel="stylesheet" MadCap:stylesheetType="table" />
        <link href="../Resources/TableStyles/p_Code.css" rel="stylesheet" MadCap:stylesheetType="table" />
        <link href="../Resources/TableStyles/p_Note.css" rel="stylesheet" MadCap:stylesheetType="table" />
        <link href="../Resources/Stylesheets/BookStyles.css" rel="stylesheet" type="text/css" />
        <script src="../SkinSupport/MadCapAll.js" type="text/javascript">
        </script>
        <script src="../SkinSupport/MadCapLiveHelpUtilities.js" type="text/javascript">
        </script>
        <script src="../SkinSupport/MadCapLiveHelpBody.js" type="text/javascript">
        </script>
        <script src="../SkinSupport/MadCapDialog.js" type="text/javascript">
        </script>
        <script src="../SkinSupport/MadCapAddCommentDialog.js" type="text/javascript">
        </script>
        <script src="../SkinSupport/MadCapReplyCommentDialog.js" type="text/javascript">
        </script>
        <script src="../SkinSupport/MadCapRegisterUserDialog.js" type="text/javascript">
        </script>
    </head>
    <body>
        <p class="MCWebHelpFramesetLink" style="display: none;"><a href="../../Default_CSH.htm#AppC - Performance/Performance_Overview.htm" style="">Open topic with navigation</a>
        </p>
        <h1 class="ChapterTitle"><a name="top"></a><a name="kanchor1262"></a>Obtaining the Best SAL Performance</h1>
        <p class="Body">The following topics provide information to help you get the best performance with SAL, regardless of the processor for which you are developing:</p>
        <ul>
            <li value="1"><a href="#Optimize" target="" title="Go to Optimized Versus Non-Optimized Code Execution" alt="Go to Optimized Versus Non-Optimized Code Execution" class="MCXref_SimpleLink"><span style="color: DarkBlue;" class="mcFormatColor">Optimized Versus Non-Optimized Code Execution</span></a>
            </li>
            <li value="2"><a href="#Common" target="" title="Go to Common Performance-Related Programming Errors" alt="Go to Common Performance-Related Programming Errors" class="MCXref_SimpleLink"><span style="color: DarkBlue;" class="mcFormatColor">Common Performance-Related Programming Errors</span></a>
            </li>
            <li value="3"><a href="#Understa" target="" title="Go to Understanding the Data Cache" alt="Go to Understanding the Data Cache" class="MCXref_SimpleLink"><span style="color: DarkBlue;" class="mcFormatColor">Understanding the Data Cache</span></a>
            </li>
            <li value="4"><a href="#Using" target="" title="Go to Using Unit Strides" alt="Go to Using Unit Strides" class="MCXref_SimpleLink"><span style="color: DarkBlue;" class="mcFormatColor">Using Unit Strides</span></a>
            </li>
            <li value="5"><a href="#Avoiding" target="" title="Go to Avoiding Thrashing in Translation Look-Aside Buffers" alt="Go to Avoiding Thrashing in Translation Look-Aside Buffers" class="MCXref_SimpleLink"><span style="color: DarkBlue;" class="mcFormatColor">Avoiding Thrashing in Translation Look-Aside Buffers</span></a>
            </li>
            <li value="6"><a href="#Using2" target="" title="Go to Using C Extension Code Instead of SAL Functions" alt="Go to Using C Extension Code Instead of SAL Functions" class="MCXref_SimpleLink"><span style="color: DarkBlue;" class="mcFormatColor">Using C Extension Code Instead of SAL Functions</span></a>
            </li>
            <li value="7"><a href="#Using_ESAL_flag" target="" title="Go to Obtaining the Best SAL Performance" alt="Go to Obtaining the Best SAL Performance" class="MCXref_SimpleLink"><span style="color: DarkBlue;" class="mcFormatColor">Using the ESAL Flag Argument</span></a>
            </li>
            <li value="8"><a href="#Using4" target="" title="Go to Using the SAL Function Timing Tables" alt="Go to Using the SAL Function Timing Tables" class="MCXref_SimpleLink"><span style="color: DarkBlue;" class="mcFormatColor">Using the SAL Function Timing Tables</span></a>
            </li>
        </ul>
        <h1 style="page-break-before: auto;page-break-after: auto;"><a name="Optimize"></a><a name="kanchor1263"></a>Optimized Versus Non-Optimized Code Execution</h1>
        <p class="Body">The SAL library is layered and has internal decision logic. Wherever possible, optimized versions of library functions are used. However, depending on the input argument conditions, it is possible that non-optimized code may be called.</p>
        <h1 style="page-break-before: auto;page-break-after: auto;"><a name="Common"></a><a name="kanchor1264"></a>Common Performance-Related Programming Errors</h1>
        <p class="Body">The most common programming errors that reduce SAL performance include:</p>
        <ul>
            <li value="1">
                <p>Uninitialized buffers </p>
                <p>In Linux, buffers must be written in order to initialize them and complete the buffer allocation process.</p>
            </li>
            <li value="2">
                <p>Non-aligned vectors or matrices </p>
                <p>For best performance, align vectors and matrices on 32-byte boundaries (ideal) or 16-byte boundaries (minimum).</p>
            </li>
            <li value="3">
                <p>Non-sequential data access (non-unit stride) </p>
                <p>For best performance, ensure that data are sequential and use a unit stride.</p>
            </li>
            <li value="4">
                <p>Incorrect use of the <code>ESAL </code>flags </p>
                <p>For best performance, create <code>ESAL </code>flags for each function that you use.</p>
            </li>
            <li value="5">The <i>tcols </i>parameter is not a multiple of 4 (2-D functions)</li>
            <li value="6">Absence of, or incorrect use of strip-mining</li>
            <li value="7">Excessive or unnecessary use of scalars or short vectors</li>
            <li value="8">Failure to link-in the optimized library</li>
            <li value="9">Failure to use profiler to diagnose bottlenecks</li>
            <li value="10">Excessive or unnecessary use of double precision</li>
            <li value="11">Excessive or unnecessary use of tables (can cause poor performance on SIMD machines)</li>
            <li value="12">
                <p>Buffers not allocated for efficiency </p>
                <p>For best performance, allocate shared memory buffers (SMBs) according to the total buffer size and partition them into contiguous buffers. SMBs can be BAT-mapped.</p>
            </li>
            <li value="13">Leaving debugging <code>printf </code>statements in the hot loop code after they are no longer useful</li>
        </ul>
        <h1 style="page-break-before: auto;page-break-after: auto;"><a name="Understa"></a><a name="kanchor1265"></a>Understanding the Data Cache</h1>
        <p class="Body">To achieve optimal data flow in your application, you must understand how to use the data and instruction caches to increase dataflow speed.</p>
        <p class="Body">For example, PowerPCs contain separate L1 data and instruction caches, and an L2 cache controller and tags which support a 0.5, 1.0, or 2.0 MB combined data/instruction cache. The performance of code and data that are located in main memory is improved when they are located in L2 cache and further improved when they are located in L1 cache.</p>
        <h2>How the PowerPC Writes to Cache</h2>
        <p class="Body">Typically, a program accesses an address in main memory, and soon after, accesses contiguous addresses. The presence of consecutive addresses in cache memory results in greater efficiency. To gain the performance efficiencies of using the cache, you should maximize use of data already in cache, and minimize cache misses.</p>
        <p class="Body">When it accesses a non-cached memory location, a PowerPC writes data into its L1 cache. It brings a cache line (32 bytes) into cache, and (usually) sends the line it replaces back to main memory.</p>
        <p class="Body">All local shared memory buffers (SMBs) are cached after you access them, to the extent that they fit into cache. Remote SMBs are not cacheable on the PPC. Therefore, it is inefficient to execute algorithms on remote SMBs. Before processing data, move it to a local SMB.</p>
        <p class="Body">Strip-mining is one technique used to manage cache access. <a href="#Strip" target="" title="Go to Strip Mining Code on the PowerPC" alt="Go to Strip Mining Code on the PowerPC" class="MCXref_See_Prefixed" MadCap:conditions="Default.PrintOnly">For more information, see <span style="color: DarkBlue;" class="mcFormatColor"><i>Strip-Mining Code on the PowerPC</i></span></a>.</p>
        <h2><a name="kanchor1266"></a>Keeping Data Cached</h2>
        <p class="Body">Moving data back and forth between the L1 or L2 caches and DRAM impedes performance. To avoid this, keep data and intermediate results in the L1 and L2 caches as long as possible.</p>
        <p class="Body">The L1 data cache has an 8-way set-associative organization and uses a least recently user (LRU) replacement policy.</p>
        <p class="Body">The PowerPC L1 cache, when loaded from a contiguous block of memory, contains most of the most recently accessed 32 KB of data. When operand and result vectors become too long to fit into L1 cache, the SAL function-per-unit execution time increases significantly.</p>
        <p class="Body">Short vectors can be kept entirely in fast L1 and L2 cache.</p>
        <p class="Body">The L2 cache is a victim cache for the L1 data cache, allocating new data entries only when blocks are cast out of the L1 data cache. It is also set-associative and uses an LRU replacement policy.</p>
        <table style="caption-side: top;width: 500px;mc-table-style: url('../Resources/TableStyles/o_Note.css');" class="TableStyle_o_Note" cellspacing="0">
            <col style="width: 100%;" />
            <tbody>
                <tr>
                    <td class="TableStyle_o_Note_Body_0_0_RowSep_ColEnd">
                        <p class="Note" MadCap:autonum="&lt;b&gt;&lt;span style=&quot;color: #06347a;&quot; class=&quot;mcFormatColor&quot;&gt;Note&lt;/span&gt;&lt;/b&gt;"><span class="autonumber"><span><b><span style="color: #06347a;" class="mcFormatColor">Note</span></b></span></span>&#160;</p>
                    </td>
                </tr>
                <tr>
                    <td class="TableStyle_o_Note_Body_0_0_RowEnd_ColEnd">Depending on the size of the L2 cache, the L2 cache contains the most recently cast out blocks from the L1 data cache (0.5, 1.0, or 2.0 MB).</td>
                </tr>
            </tbody>
        </table>
        <p class="Body">The L1 and L2 cache data access bandwidth is significantly greater than that of DRAM. As a result, DRAM-to-DRAM operations are much slower than corresponding L1 cache-to-cache operations.</p>
        <h2><a name="Strip"></a><a name="kanchor1267"></a>Strip-Mining Code on the PowerPC</h2>
        <p class="Body">Processing large data sets with incorrect use of high-speed caches can degrade the effective memory access speed to the point where it is slower than it would be without the caches. Some vectors are too large to fit in their entirety into cache. Strip-mining is a technique of partitioning large data sets into pieces that fit into caches, and revising each strip of data for as many calculations as possible while the data reside in cache.</p>
        <h2><a name="kanchor1268"></a>Strip-Mining Process</h2>
        <p class="BodyLeadIn">The strip-mining process:</p>
        <ol>
            <li value="1">Pulls a strip of the data stream into the L1 or L2 cache.</li>
            <li value="2">Works on the strip until all required operations are complete.</li>
            <li value="3">Loads the next strip, which expels the old data from the L1 to the L2 cache.</li>
        </ol>
        <p class="Body">The data moves from DRAM or any other slower cache once. The difference in speed can be hundreds of percent.</p>
        <p class="Body">In <a href="#Non-Strip_Mining" target="" title="" alt="" class="MCXref_FigTabExam"><span style="color: DarkBlue;" class="mcFormatColor">Example 12-3</span></a>, data is brought into the data cache by the SAL <code>vfillx()</code> function.</p>
        <p class="CaptionNumChap_Example" MadCap:autonum="&lt;b&gt;Example 12-3: &lt;/b&gt;"><span class="autonumber"><span><b>Example 12-3: </b></span></span><a name="Non-Strip_Mining"></a>Non-Strip Mining (slow)</p>
        <table style="caption-side: top;width: 500px;mc-table-style: url('../Resources/TableStyles/o_Code.css');" class="TableStyle_o_Code" cellspacing="0">
            <col style="width: 499px;" />
            <tbody>
                <tr>
                    <td class="TableStyle_o_Code_Body_0_0_RowEnd_ColEnd">
                        <p>main()</p>
                        <p>{	SAL_f32 a[1024*1024],sum, fill_value;</p>
                        <p class="Code1">vfillx(&amp;fill_value, a, 1, 1024*1024, 0);</p>
                        <p class="Code1">vsaddx(a,1,&amp;one,a,1,1024*1024,0);</p>
                        <p class="Code1">svex(a, 1, &amp;sum, 1024*1024, 0);</p>
                        <p class="Code1">printf("sum= %f\n",sum);</p>
                        <p>}</p>
                    </td>
                </tr>
            </tbody>
        </table>
        <p class="Body">Accessing data from L1 and L2 cache is ten to twenty times faster than getting data from DRAM. Depending on the relative speed of the L2 cache, L1 access is slightly faster than L2 access.</p>
        <table style="width: 500px;caption-side: top;mc-table-style: url('../Resources/TableStyles/o_Note.css');" class="TableStyle_o_Note" cellspacing="0">
            <col style="width: 500px;" />
            <tbody>
                <tr>
                    <td class="TableStyle_o_Note_Body_0_0_RowSep_ColEnd">
                        <p class="Note" MadCap:autonum="&lt;b&gt;&lt;span style=&quot;color: #06347a;&quot; class=&quot;mcFormatColor&quot;&gt;Note&lt;/span&gt;&lt;/b&gt;"><span class="autonumber"><span><b><span style="color: #06347a;" class="mcFormatColor">Note</span></b></span></span>&#160;</p>
                    </td>
                </tr>
                <tr>
                    <td class="TableStyle_o_Note_Body_0_0_RowEnd_ColEnd">Cache architecture depends on the particular microprocessor. For more information on a chip’s cache architecture, see the microprocessor user documentation.</td>
                </tr>
            </tbody>
        </table>
        <h2><a name="kanchor1269"></a>Strip Mining Code Example</h2>
        <p class="Body">Because an entire 1MB point array cannot fit into the L1 data cache, it is better to process the code in 32KB (8K float) strips. </p>
        <p class="Body"><a href="#Strip-mining_example" target="" title="" alt="" class="MCXref_FigTabExam"><span style="color: DarkBlue;" class="mcFormatColor">Example 12-4</span></a> provides a code fragment that is a basic example of strip-mining in a sequence of calls to strip-mine L1 cache, which holds 8K floats. The code in this example is twice as fast as the code in<a href="#Non-Strip_Mining" target="" title="" alt="" class="MCXref_FigTabExam"><span style="color: DarkBlue;" class="mcFormatColor">Example 12-3</span></a>. If you perform many functions on the same piece of data, the performance gain is even greater.</p>
        <p class="CaptionNumChap_Example" MadCap:autonum="&lt;b&gt;Example 12-4: &lt;/b&gt;"><span class="autonumber"><span><b>Example 12-4: </b></span></span><a name="Strip-mining_example"></a>Using a sequence of calls to strip-mine L1 cache</p>
        <table style="caption-side: top;width: 500px;mc-table-style: url('../Resources/TableStyles/o_Code.css');" class="TableStyle_o_Code" cellspacing="0">
            <col style="width: 501px;" />
            <tbody>
                <tr>
                    <td class="TableStyle_o_Code_Body_0_0_RowEnd_ColEnd">
                        <p>main()</p>
                        <p>{	SAL_f32 a[1024*1024], sum1, sum2, sum3, sum4, sum;</p>
                        <p>// STEP 1: Fill and process first 1M block, put result in sum1;</p>
                        <p>// STEP 2: Fill and process second 1M block, put result to sum2;</p>
                        <p>// STEP 3: Fill and process third 1M block, put result to sum3;</p>
                        <p>// STEP 4: Fill and process fourth 1M block, put result into sum4;</p>
                        <p>// STEP 5: sum = sum1 + sum2 + sum3 + sum4;</p>
                        <p>}</p>
                        <p>{ 	SAL_f32 *a_tmp = a, *b_tmp = b, *c_tmp = c;</p>
                        <p class="Code1">SAL_f32 sc = 1.25;</p>
                        <p class="Code1">SAL_f32 sum = 0.0;</p>
                        <p class="Code1">SAL_ui32 i, remainder;</p>
                        <p class="Code1">NUM_STRIPS = POINTS/STRIP_POINTS;</p>
                        <p class="Code1">vrampx(&amp;one,&amp;one,a,1,Points,0);</p>
                        <p class="Code1">for (i = 0; i &lt; NUM_STRIPS; ++i)</p>
                        <p class="Code1">{ 	vsaddx(a_tmp, 1, &amp;sc, a_tmp, 1, STRIP_POINTS, SAL_NC);</p>
                        <p class="Code2">svex(a_tmp, 1, &amp;sum, STRIP_POINTS, SAL_C);</p>
                        <p class="Code2">a_tmp += STRIP_POINTS;</p>
                        <p class="Code1">}</p>
                        <p class="Code1">remainder = POINTS % STRIP_POINTS;</p>
                        <p class="Code1">if (remainder)</p>
                        <p class="Code1">{	vsaddx(a_tmp, 1, &amp;sc, a_tmp, 1, remainder, SAL_NC);</p>
                        <p class="Code1">svex(a_tmp, 1, &amp;sum, remainder, SAL_C);</p>
                        <p class="Code1">}</p>
                        <p>}</p>
                    </td>
                </tr>
            </tbody>
        </table>
        <h1 style="page-break-before: auto;page-break-after: auto;"><a name="Using"></a><a name="kanchor1270"></a>Using Unit Strides</h1>
        <p class="Body">Because accessing operands or results with non-unit strides reduces SAL function performance, use unit strides whenever possible. On AltiVec-based PowerPCs, you should use unit strides in SAL functions to get AltiVec-optimized loops. For information about how to configure stride lengths to enhance performance, see <a href="../CH01 - Introduction/Calling_Conventions.htm#Address_strides" target="" title="Go to Address Strides" alt="Go to Address Strides" class="MCXref_See_NoPrefix" MadCap:conditions="Default.ScreenOnly"><span style="color: DarkBlue;" class="mcFormatColor"><i>Address Strides</i></span></a>.</p>
        <h1 style="page-break-before: auto;page-break-after: auto;"><a name="Avoiding"></a><a name="kanchor1271"></a>Avoiding Thrashing in Translation Look-Aside Buffers</h1>
        <p class="Body">The translation look-aside buffer (TLB) is a multi-entry, two-way, set-associative cache that provides fast virtual-to-physical memory address translation. Excessively updating the TLB reduces performance. To minimize the number of TLB updates, consider the order in which your application accesses data.</p>
        <p class="Body">A TLB miss happens whenever you access a memory location on another DRAM page. The hardware automatically updates the TLB contents to include an entry for the new memory page.</p>
        <p class="Body">Excessive updating, called TLB thrashing, occurs for two reasons:</p>
        <ul>
            <li value="1">
                <p>The range of accessed addresses exceeds the TLB total address range. </p>
                <p>All SAL function arguments combined span a range of addresses (not necessarily contiguous) in excess of the TLB address range.</p>
            </li>
            <li value="2">
                <p>The addresses of more than two arguments are separated by a multiple of half the TLB address range. </p>
                <p>This relates more to the relative address alignment between different SAL function vector arguments than to the argument lengths.</p>
            </li>
        </ul>
        <p class="Body">To minimize the effect of thrashing, change the order in which the program accesses the data. For example, transposing column-organized data into row-organized data before working with it improves performance.</p>
        <p class="Body">To eliminate TLB thrashing, enable block address translation (BAT) mapping, to translate the virtual-to-physical address translation by way of the BAT register. The stack and heap always use the TLB.</p>
        <p class="Body">SMBs can be BAT-mapped. Check the documentation for your specific chassis.</p>
        <p class="Body">Keep in mind that BAT mapping does not offer the memory protection on a page-by-page basis that is provided by TLB mapping. Enable BAT mapping only after you have debugged your application.</p>
        <h1 style="page-break-before: auto;page-break-after: auto;"><a name="Using2"></a><a name="kanchor1272"></a>Using C Extension Code Instead of SAL Functions</h1>
        <p class="Body">On the PowerPC, SAL functions do not always provide better performance than compiled C code. Because every SAL function is standalone, it should always access its operands from L1 cache and write its results back to that cache. Optimal performance occurs only when all operand and result addresses are previously cached in L1, so that the SAL function does not have to make L2 or DRAM accesses.</p>
        <p class="Body">Instead of using a series of SAL functions, consider writing elaborate, multi-step calculations directly in C code. The compiler automatically stores and reuses intermediate results in the CPU internal registers, which is much faster than access from the L1 cache.</p>
        <p class="Body">You can attain higher performance (approaching the PowerPC CPU’s theoretical limit) by retaining the intermediate compound computation results (those normally implemented by a sequence of SAL calls) in the CPU internal registers (instead of writing them back to L1 cache). This technique is used by some of the more complex SAL functions, such as FFTs and direct convolution.</p>
        <p class="Body">You must evaluate whether implementing an algorithm directly in C extension code is more efficient than calling a corresponding sequence of SAL functions on a case-by-case basis. For example, on AltiVec-based PowerPCs, you can use the C extensions to gain access to the AltiVec instruction set.</p>
        <h1 style="page-break-before: auto;page-break-after: auto;"><a name="Using_ESAL_flag"></a><a name="kanchor1273"></a>Using the ESAL Flag Argument</h1>
        <p class="Body">Most SAL functions include an <code>ESAL </code>flag as the last argument in their function call. The <code>ESAL </code>flag improves execution time by providing hints about whether each vector or matrix argument is in cache or not, enabling the function to access data more quickly.</p>
        <p class="Body">The <code>ESAL </code>flag is written as SAL_ followed by a series of <i>C</i>s and <i>N</i>s, for example:</p>
        <p class="Body1"><code>SAL_NCC</code> <![CDATA[ ]]></p>
        <p class="Body1">where:</p>
        <ul>
            <li class="Bullet1" value="1"><i>C</i> stands for a buffer in L1 cache</li>
            <li class="Bullet1" value="2"><i>N</i> stands for a buffer not in L1 cache</li>
        </ul>
        <p class="Body">The order of letters is the same as the order of buffer parameters in the call. So, in this example, the function call includes three buffer parameters. The first is in non-L1 cache, and the second and third are in L1 cache.</p>
        <p class="Body">The <code>ESAL </code>flag includes an <i>N </i>or <i>C </i>for each buffer parameter (vector or matrix) of the function. Any combination of <i>C</i>s and <i>N</i>s is valid. The default value for the <code>ESAL </code>flag is zero; no buffers are resident in the L1 cache.</p>
        <p class="Body">Erroneous <code>ESAL </code>flags do not cause functions to fail, but they might reduce performance. C-SAL and non-AltiVec-optimized SAL routines might ignore the <code>ESAL </code>flag.</p>
        <h2><a name="kanchor1274"></a>ESAL Flag Example</h2>
        <p class="Body">In this example, the SAL function sequence is: <code>vaddx()</code>, <code>vmulx()</code>, <code>vamx(</code>)</p>
        <p class="Body">If:</p>
        <ul>
            <li value="1"><i>N </i>is 1024</li>
            <li value="2"><i>pSrc0</i>, <i>pSrc1</i>, <i>pSrc2</i>, <i>pSrc3</i>, <i>pSrc4</i>, <i>pSrcDst</i>, and <i>pDst </i>are pointers to distinct floating point vectors, each with 1024 float elements initially located in DRAM</li>
        </ul>
        <table style="width: 500px;caption-side: top;mc-table-style: url('../Resources/TableStyles/o_Note.css');" class="TableStyle_o_Note" cellspacing="0">
            <col style="width: 500px;" />
            <tbody>
                <tr>
                    <td class="TableStyle_o_Note_Body_0_0_RowSep_ColEnd">
                        <p class="Note" MadCap:autonum="&lt;b&gt;&lt;span style=&quot;color: #06347a;&quot; class=&quot;mcFormatColor&quot;&gt;Note&lt;/span&gt;&lt;/b&gt;"><span class="autonumber"><span><b><span style="color: #06347a;" class="mcFormatColor">Note</span></b></span></span>&#160;</p>
                    </td>
                </tr>
                <tr>
                    <td class="TableStyle_o_Note_Body_0_0_RowEnd_ColEnd">The total buffer size is 7 x 4KB = 28KB, which fits within the 32KB L1 cache. Therefore, after all buffers are loaded into cache, they can remain there for the duration of the calculation.</td>
                </tr>
            </tbody>
        </table>
        <p class="Body">The SAL call sequence is:</p>
        <ol>
            <li value="1">
                <p><code>vaddx ( pSrc0, 1, pSrc1, 1, pSrcDst, 1, N, SAL_NNN );</code> <![CDATA[ ]]></p>
                <p>All three vectors are located in DRAM, so the <code>ESAL </code>flag has three <i>N</i>s, one for each vector. <code>SAL_NNN</code>=<span style="font-family: 'Times New Roman';">0</span>.</p>
            </li>
            <li value="2">
                <p><code>vmulx ( pSrcDst, 1, pSrc2, 1, pSrcDst, 1, N, SAL_CNC );</code> <![CDATA[ ]]></p>
                <p>Because the <i>pSrcDst </i>input/output buffer was accessed previously, it resides in the L1 cache when <code>vmulx()</code> is called. </p>
                <p>Because the input/output buffer is resident in the L1 cache and the second input buffer is located in DRAM, the <code>ESAL </code>flag is <code>SAL_CNC</code>.</p>
            </li>
            <li value="3">
                <p><code>vamx ( pSrcDst, 1, pSrc3, 1, pSrc4, 1, pDst, 1, N, SAL_CNNN );</code> <![CDATA[ ]]></p>
                <p>Here, the <code>vmulx()</code> output vector is an input. Because the vectors are 4KB, the <i>pSrcDst </i>buffer is still in L1 cache. The other two input buffers and the output buffer are all located in DRAM. Therefore, the <code>ESAL </code>flag passed to <code>vamx()</code> is <code>SAL_CNNN</code>.</p>
            </li>
        </ol>
        <h2><a name="kanchor1275"></a>Implementing ESAL Flags</h2>
        <p class="Body">SAL implementations for some processors ignore the <code>ESAL </code>flag. Implementations for other processors support a subset of all possible combinations.</p>
        <ul>
            <li value="1">
                <p><b>PPC 603, PPC 750 </b>
                </p>
                <p>Most functions ignore the <code>ESAL </code>flag. Only data movement functions (move, transpose, and so on) use the flag. You can use PowerPC processor-specific instructions to pipeline the addressing or asynchronous pre-fetching of data that is not in L1 cache and is marked with an <i>N </i>in the <code>ESAL </code>flag.</p>
            </li>
            <li value="2">
                <p><b>PPC 7400, PPC 7410 </b>
                </p>
                <p>The <i>C </i>value indicates that the buffer is already resident in the L1 cache. Therefore, no action is taken to prefetch this buffer.</p>
            </li>
            <li class="Bullet1" value="3">
                <p>Input Buffers</p>
                <p>SAL prefetches the first <i>N</i>-marked input vector with fine-grained DSTs. All other <i>N</i>-marked input vectors are not prefetched.</p>
            </li>
            <li class="Bullet1" value="4">
                <p>Output Buffers</p>
                <p>SAL does not prefetch <i>N</i>-marked output vectors because it is not necessary. The SAL routines instead take advantage of the store miss-merging feature of the processor.</p>
            </li>
            <li value="5">
                <p><b>PPC 7445, PPC 7447, 7448, 864x, e600 core </b>
                </p>
                <p>The <i>C </i>value means that the buffer is already resident in the L1 cache. Therefore, no action is taken to pre-fetch this buffer.</p>
            </li>
            <li class="Bullet1" value="6">
                <p>Input Buffers</p>
                <p>Most AltiVec-optimized routines can perform internal strip mining of prefetches.</p>
            </li>
            <li class="Bullet2" value="7">If the combined input and output buffer fits into the L1 cache (32KB), the routine prefetch buffers that have been designated by an <i>N </i>(<code>SAL_N</code>) into the L1 cache, avoiding load miss queue (LMQ) stalls.</li>
            <li class="Bullet2" value="8">If the combined input and output buffer exceeds the L1 cache size (32KB), the routines prefetch strips of the input buffers that have been designated by an <i>N </i>(<code>SAL_N</code>), and place the strips into the L1 cache.</li>
            <li class="Bullet1" value="9">
                <p>Output Buffers</p>
                <p>If an <i>N </i>corresponds to an output vector, no pre-loading is performed on that vector. SAL routine store instructions take advantage of store miss-merging. Because the complete cache line is overwritten by the store set, the processor does not have to load the cache line that corresponds to the memory location updated by a store instruction set.</p>
            </li>
        </ul>
        <h1 style="page-break-before: auto;page-break-after: auto;"><a name="Using4"></a><a name="kanchor1276"></a>Using the SAL Function Timing Tables</h1>
        <p class="Body">To help you estimate potential application performance, SAL function timing data are available on the <a href="https://customers.mc.com/" title="Visit Mercury customer Web site" alt="Visit Mercury customer Web site">Mercury Customer Web site</a>. To access the timing information for your specific processor, click <span class="Keyword">Algorithm Timings </span>and then click <span class="Keyword">SAL Timings</span>.</p>
        <p class="Body">The timings are the result of actual Mercury benchmarks run on various processors. These benchmarks use random data with a stride of 1, run on a single processor with BAT mapping enabled (to eliminate TLB misses).</p>
        <p class="Body">In the SAL Timing Documents on the <a href="https://customers.mc.com/" title="Visit Mercury customer Web site" alt="Visit Mercury customer Web site">Mercury Customer Web site</a>, you can find separate times for accessing L1, L2, and DRAM.</p>
        <h2><a name="kanchor1277"></a>Data Location</h2>
        <p class="Body">SAL function performance depends on the initial location of the data buffers (in L1 cache, L2 cache, or in DRAM only).</p>
        <p class="Body">For each SAL function, the tables provide timings for the following combinations of input/output buffer locations:</p>
        <ul>
            <li value="1">All function arguments reside in the L1 cache: (L1 -&gt; L1)</li>
            <li value="2">None of the function arguments reside in the L1 cache, but all reside in the L2 cache: (L2 -&gt; L2)</li>
            <li value="3">None of the function arguments reside in L1 or L2 caches; all reside in synchronous DRAM (SDRAM): (SDRAM -&gt; SDRAM)</li>
            <li value="4">All function arguments reside at the highest level of the hierarchy where they will fit. This “best fit” approach is denoted by “B” in the SAL Function Timing Tables that are located on the <a href="https://customers.mc.com/" title="Visit Mercury customer Web site" alt="Visit Mercury customer Web site">Mercury Customer Web site</a>.</li>
        </ul>
        <p class="Body">The L1 -&gt; L1 and SDRAM -&gt; SDRAM timings define the function execution time upper and lower bounds. Depending on the length of the operand vectors and the current state of cache, SAL function performance is between the upper and lower timing bounds.</p>
        <table style="width: 500px;caption-side: top;mc-table-style: url('../Resources/TableStyles/o_Note.css');" class="TableStyle_o_Note" cellspacing="0">
            <col style="width: 500px;" />
            <tbody>
                <tr>
                    <td class="TableStyle_o_Note_Body_0_0_RowSep_ColEnd">
                        <p class="Note" MadCap:autonum="&lt;b&gt;&lt;span style=&quot;color: #06347a;&quot; class=&quot;mcFormatColor&quot;&gt;Note&lt;/span&gt;&lt;/b&gt;"><span class="autonumber"><span><b><span style="color: #06347a;" class="mcFormatColor">Note</span></b></span></span>&#160;</p>
                    </td>
                </tr>
                <tr>
                    <td class="TableStyle_o_Note_Body_0_0_RowEnd_ColEnd">The most frequently used routines are assembly code optimized. Other routines, for which no timings are given, are still available as C-coded functions. Although these C-coded routines operate correctly, they are slower than comparable assembly routines.</td>
                </tr>
            </tbody>
        </table>
        <h2><a name="kanchor1278"></a>Interpreting SAL Timings</h2>
        <p class="Body">The timing data for each routine includes:</p>
        <table style="caption-side: top; mc-table-style: url('../Resources/TableStyles/o_Invisible.css'); width: 500px;" class="TableStyle_o_Invisible" cellspacing="0">
            <col style="width: 95px;" />
            <col style="width: 368px;" />
            <tr>
                <td class="TableStyle_o_Invisible_Body_0_0_RowSep_ColSep" style="font-weight: bold;">Routine</td>
                <td class="TableStyle_o_Invisible_Body_0_0_RowSep_ColEnd">The function name</td>
            </tr>
            <tr>
                <td class="TableStyle_o_Invisible_Body_0_0_RowSep_ColSep" style="font-weight: bold;">Call Arguments</td>
                <td class="TableStyle_o_Invisible_Body_0_0_RowSep_ColEnd">The size of the data (in elements) for which the routine was timed</td>
            </tr>
            <tr>
                <td class="TableStyle_o_Invisible_Body_0_0_RowSep_ColSep" style="font-weight: bold;">Location</td>
                <td class="TableStyle_o_Invisible_Body_0_0_RowSep_ColEnd">The location (L1 cache, L2 cache, DRAM, or “best fit”) of the input data at the start of the function call and the location of the output data after the function has been completed</td>
            </tr>
            <tr>
                <td class="TableStyle_o_Invisible_Body_0_0_RowSep_ColSep" style="font-weight: bold;">Time/Call</td>
                <td class="TableStyle_o_Invisible_Body_0_0_RowSep_ColEnd">The total measured execution time (in microseconds) for the vector length specified by the call argument</td>
            </tr>
            <tr>
                <td class="TableStyle_o_Invisible_Body_0_0_RowSep_ColSep" style="font-weight: bold;">Time/Pt</td>
                <td class="TableStyle_o_Invisible_Body_0_0_RowSep_ColEnd">The execution time per data point (in microseconds per point)</td>
            </tr>
            <tr>
                <td class="TableStyle_o_Invisible_Body_0_0_RowSep_ColSep" style="font-weight: bold;">Mflops</td>
                <td class="TableStyle_o_Invisible_Body_0_0_RowSep_ColEnd">The execution speed (in Mflops)</td>
            </tr>
            <tr>
                <td class="TableStyle_o_Invisible_Body_0_0_RowSep_ColSep" style="font-weight: bold;">Ovhd/Call</td>
                <td class="TableStyle_o_Invisible_Body_0_0_RowSep_ColEnd">The overhead time for calling the routine (in microseconds)</td>
            </tr>
        </table>
        <p class="Body">To determine a routine’s execution time for processing a vector of length <i>N</i>, multiply the time/point by the vector length, and then add the associated overhead time.</p>
        <p class="Body">For example, the execution time required to process a 64-point data vector is:</p>
        <table class="TableStyle_o_Invisible" style="mc-table-style: url('../Resources/TableStyles/o_Invisible.css');width: 461px;" cellspacing="0">
            <col style="width: 151px;" />
            <col style="width: 100%;" />
            <tbody>
                <tr>
                    <td class="TableStyle_o_Invisible_Body_0_0_RowSep_ColSep" style="font-weight: bold;">Execution time per point</td>
                    <td class="TableStyle_o_Invisible_Body_0_0_RowSep_ColEnd">0.05 μs</td>
                </tr>
                <tr>
                    <td class="TableStyle_o_Invisible_Body_0_0_RowSep_ColSep" style="font-weight: bold;">Overhead time</td>
                    <td class="TableStyle_o_Invisible_Body_0_0_RowSep_ColEnd">0.15 μs</td>
                </tr>
                <tr>
                    <td class="TableStyle_o_Invisible_Body_0_0_RowEnd_ColSep" style="font-weight: bold;">Total execution time</td>
                    <td class="TableStyle_o_Invisible_Body_0_0_RowEnd_ColEnd">(64 X 0.05) + 0.15 = 3.35μs</td>
                </tr>
            </tbody>
        </table>
        <h2><a name="kanchor1279"></a>Convolution Routine Timings</h2>
        <p class="Body">The <code><a href="../CH12 - Functions - CCF_Image_Processing/1-D/Convolution and Correlation.htm#convx">convx()</a></code>, <code><a href="../CH12 - Functions - CCF_Image_Processing/1-D/Convolution and Correlation.htm#cconvx">cconvx()</a></code>, and <code><a href="../CH12 - Functions - CCF_Image_Processing/1-D/Complex-Real Down Sample.htm#desampx">desampx()</a></code> function execution times are based on:</p>
        <table class="TableStyle_o_Invisible" style="mc-table-style: url('../Resources/TableStyles/o_Invisible.css');width: 461px;" cellspacing="0">
            <col style="width: 100%;" />
            <col style="width: 100%;" />
            <tbody>
                <tr>
                    <td class="TableStyle_o_Invisible_Body_0_0_RowSep_ColSep">Data vector length</td>
                    <td class="TableStyle_o_Invisible_Body_0_0_RowSep_ColEnd">1,024</td>
                </tr>
                <tr>
                    <td class="TableStyle_o_Invisible_Body_0_0_RowEnd_ColSep">Filter vector lengths</td>
                    <td class="TableStyle_o_Invisible_Body_0_0_RowEnd_ColEnd">8 to 64 points</td>
                </tr>
            </tbody>
        </table>
        <p class="Body">Execution times are proportional to the length of the desampled output vector.</p>
        <p class="Body">Execution times for the desampx() function are for an f=3 down-sampling factor. Other than the down-sampling factor, the desampx() function execution times are similar to the convx() function times for the same output vector length and filter length.</p>
        <p class="Body">Execution times are proportional to the product of the output data and filter vector lengths. Therefore, for the same filter length, the execution time for an output data vector length of 256 is 25 percent of the time listed for a length of 1,024.</p>
        <p class="Body">For a one-shot convolution, the length of the data is padded on both ends with zeros. For example:</p>
        <p class="Body1"><code>0000000&lt;data&gt;000000000</code> <![CDATA[ ]]></p>
        <p class="Body">The leading zeros are called the “wind out” and the trailing zeros are called the “wind in.” Both are equal to “Length of Filter - 1.”</p>
        <p class="Body">For more information on the SAL convolution and down-sampling routines, see <a href="../CH02 - Transform Functions/SAL_CCFs.htm" target="" title="" alt="" class="MCXref_See_NoPrefix" MadCap:conditions="Default.ScreenOnly"><span style="color: DarkBlue;" class="mcFormatColor"><i>SAL Convolution and Correlation Functions</i></span></a>.</p>
        <script type="text/javascript" src="../SkinSupport/MadCapBodyEnd.js">
        </script><iframe id="topiccomments" name="topiccomments" title="Topic Comments" src="../../Skin/TopicComments.htm" frameborder="0" style="width: 100%; height: 0px; margin-top: 12px;"></iframe>
    </body>
</html>